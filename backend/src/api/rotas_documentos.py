"""
Rotas de Documentos - API de Upload e Gest√£o de Documentos

CONTEXTO DE NEG√ìCIO:
Este m√≥dulo implementa todos os endpoints relacionados a documentos jur√≠dicos:
- Upload de arquivos (PDF, DOCX, imagens)
- Listagem de documentos
- Consulta de status de processamento

RESPONSABILIDADE:
- Receber arquivos via HTTP multipart/form-data
- Validar tipo e tamanho de arquivo
- Salvar arquivos em pasta tempor√°ria
- Gerar UUIDs √∫nicos para cada documento
- Retornar metadados dos documentos

FLUXO DE UPLOAD:
1. Cliente envia arquivo(s) via POST
2. Validamos extens√£o e tamanho
3. Geramos UUID √∫nico
4. Salvamos em uploads_temp/
5. Retornamos informa√ß√µes do documento
6. (Futuro) Processamento ass√≠ncrono extrai texto

JUSTIFICATIVA PARA LLMs:
- APIRouter permite modulariza√ß√£o de rotas
- Valida√ß√µes expl√≠citas com mensagens claras de erro
- Logging detalhado para debug
- Fun√ß√µes auxiliares pequenas e focadas
"""

from fastapi import APIRouter, UploadFile, File, HTTPException, status, BackgroundTasks
from typing import List, Dict, Any
import uuid
import os
from pathlib import Path
import logging
from datetime import datetime

# Importar modelos de resposta
from src.api.modelos import (
    RespostaUploadDocumento,
    InformacaoDocumentoUploadado,
    TipoDocumentoEnum,
    StatusProcessamentoEnum,
    RespostaErro,
    StatusDocumento,
    RespostaListarDocumentos,
    RespostaDeletarDocumento,
    ResultadoProcessamentoDocumento,
    RespostaIniciarUpload,
    RespostaStatusUpload,
    RespostaResultadoUpload
)

# Importar configura√ß√µes
from src.configuracao.configuracoes import obter_configuracoes

# Importar servi√ßos
from src.servicos import servico_ingestao_documentos
from src.servicos import servico_banco_vetorial
from src.servicos.gerenciador_estado_uploads import obter_gerenciador_estado_uploads


# ===== CONFIGURA√á√ÉO DO ROUTER =====

router = APIRouter(
    prefix="/api/documentos",
    tags=["Documentos"],
    responses={
        413: {
            "description": "Arquivo muito grande",
            "model": RespostaErro
        },
        415: {
            "description": "Tipo de arquivo n√£o suportado",
            "model": RespostaErro
        }
    }
)


# ===== CONFIGURA√á√ÉO DE LOGGING =====

logger = logging.getLogger(__name__)


# ===== OBTER CONFIGURA√á√ïES =====

configuracoes = obter_configuracoes()


# ===== ARMAZENAMENTO EM MEM√ìRIA DE STATUS =====
# NOTA: Em produ√ß√£o, isso deve ser substitu√≠do por um banco de dados
# Por agora, usamos um dict em mem√≥ria para rastrear status dos documentos

documentos_status_cache: Dict[str, Dict[str, Any]] = {}


# ===== CONSTANTES =====

# Tipos de arquivo aceitos (extens√µes v√°lidas)
EXTENSOES_PERMITIDAS = {".pdf", ".docx", ".png", ".jpg", ".jpeg"}

# Mapeamento de extens√£o para enum
MAPEAMENTO_EXTENSAO_PARA_TIPO = {
    ".pdf": TipoDocumentoEnum.PDF,
    ".docx": TipoDocumentoEnum.DOCX,
    ".png": TipoDocumentoEnum.PNG,
    ".jpg": TipoDocumentoEnum.JPG,
    ".jpeg": TipoDocumentoEnum.JPEG,
}


# ===== FUN√á√ïES AUXILIARES =====

def obter_extensao_do_arquivo(nome_arquivo: str) -> str:
    """
    Extrai a extens√£o de um nome de arquivo.
    
    CONTEXTO:
    Precisamos validar a extens√£o do arquivo para garantir que apenas
    tipos suportados sejam aceitos (PDF, DOCX, imagens).
    
    IMPLEMENTA√á√ÉO:
    Usa pathlib.Path para extrair a extens√£o de forma robusta.
    Converte para min√∫sculas para compara√ß√£o case-insensitive.
    
    Args:
        nome_arquivo: Nome do arquivo (ex: "processo_123.PDF")
    
    Returns:
        Extens√£o em min√∫sculas com ponto (ex: ".pdf")
    
    Examples:
        >>> obter_extensao_do_arquivo("documento.PDF")
        ".pdf"
        >>> obter_extensao_do_arquivo("imagem.JPG")
        ".jpg"
    """
    extensao = Path(nome_arquivo).suffix.lower()
    return extensao


def validar_tipo_de_arquivo(nome_arquivo: str) -> bool:
    """
    Valida se o tipo de arquivo √© aceito pelo sistema.
    
    CONTEXTO:
    Por seguran√ßa e limita√ß√£o de processamento, aceitamos apenas
    tipos espec√≠ficos de documentos jur√≠dicos.
    
    TIPOS ACEITOS:
    - PDF: Documentos em formato PDF
    - DOCX: Documentos do Microsoft Word
    - PNG/JPG/JPEG: Imagens escaneadas
    
    Args:
        nome_arquivo: Nome do arquivo a validar
    
    Returns:
        True se o tipo for aceito, False caso contr√°rio
    
    Examples:
        >>> validar_tipo_de_arquivo("processo.pdf")
        True
        >>> validar_tipo_de_arquivo("planilha.xlsx")
        False
    """
    extensao = obter_extensao_do_arquivo(nome_arquivo)
    return extensao in EXTENSOES_PERMITIDAS


def validar_tamanho_de_arquivo(tamanho_em_bytes: int) -> bool:
    """
    Valida se o tamanho do arquivo est√° dentro do limite permitido.
    
    CONTEXTO:
    Para evitar sobrecarga do servidor e problemas de mem√≥ria,
    limitamos o tamanho m√°ximo de cada arquivo.
    
    LIMITE ATUAL:
    Configur√°vel via TAMANHO_MAXIMO_ARQUIVO_MB (padr√£o: 50MB)
    
    Args:
        tamanho_em_bytes: Tamanho do arquivo em bytes
    
    Returns:
        True se o tamanho for aceit√°vel, False se exceder o limite
    
    Examples:
        >>> validar_tamanho_de_arquivo(1024 * 1024 * 10)  # 10MB
        True
        >>> validar_tamanho_de_arquivo(1024 * 1024 * 100)  # 100MB
        False
    """
    tamanho_maximo_bytes = configuracoes.TAMANHO_MAXIMO_ARQUIVO_MB * 1024 * 1024
    return tamanho_em_bytes <= tamanho_maximo_bytes


def gerar_nome_arquivo_unico(extensao: str) -> tuple[str, str]:
    """
    Gera um UUID √∫nico e um nome de arquivo correspondente.
    
    CONTEXTO:
    Para evitar conflitos de nomes e rastrear documentos unicamente,
    geramos um UUID v4 para cada arquivo.
    
    IMPLEMENTA√á√ÉO:
    1. Gera UUID v4 aleat√≥rio
    2. Converte para string
    3. Cria nome de arquivo: {uuid}{extensao}
    
    Args:
        extensao: Extens√£o do arquivo (ex: ".pdf")
    
    Returns:
        Tupla (id_documento, nome_arquivo)
        - id_documento: UUID como string
        - nome_arquivo: UUID + extens√£o (ex: "550e8400-e29b-41d4-a716-446655440000.pdf")
    
    Examples:
        >>> gerar_nome_arquivo_unico(".pdf")
        ("550e8400-e29b-41d4-a716-446655440000", "550e8400-e29b-41d4-a716-446655440000.pdf")
    """
    id_documento = str(uuid.uuid4())
    nome_arquivo = f"{id_documento}{extensao}"
    return id_documento, nome_arquivo


def obter_caminho_pasta_uploads_temp() -> Path:
    """
    Retorna o caminho da pasta de uploads tempor√°rios.
    
    CONTEXTO:
    Arquivos s√£o salvos temporariamente enquanto aguardam processamento.
    Ap√≥s extra√ß√£o de texto e vetoriza√ß√£o, os arquivos podem ser movidos
    ou deletados (dependendo da configura√ß√£o).
    
    IMPLEMENTA√á√ÉO:
    L√™ o caminho da configura√ß√£o e garante que a pasta existe.
    
    Returns:
        Path object apontando para a pasta de uploads tempor√°rios
    
    Raises:
        OSError: Se n√£o for poss√≠vel criar a pasta
    """
    caminho_pasta = Path(configuracoes.CAMINHO_UPLOADS_TEMP)
    
    # Criar pasta se n√£o existir
    # exist_ok=True evita erro se a pasta j√° existir
    caminho_pasta.mkdir(parents=True, exist_ok=True)
    
    return caminho_pasta


async def salvar_arquivo_no_disco(
    arquivo_upload: UploadFile,
    caminho_destino: Path
) -> int:
    """
    Salva um arquivo enviado via upload no sistema de arquivos.
    
    CONTEXTO:
    FastAPI UploadFile √© um objeto SpooledTemporaryFile que mant√©m
    o arquivo em mem√≥ria (at√© certo tamanho) ou em disco tempor√°rio.
    Precisamos salv√°-lo permanentemente na nossa pasta de uploads.
    
    IMPLEMENTA√á√ÉO:
    L√™ o arquivo em chunks para evitar consumo excessivo de mem√≥ria
    em arquivos grandes.
    
    Args:
        arquivo_upload: Objeto UploadFile do FastAPI
        caminho_destino: Path onde o arquivo ser√° salvo
    
    Returns:
        N√∫mero de bytes escritos (tamanho do arquivo)
    
    Raises:
        IOError: Se houver erro ao escrever no disco
    
    OTIMIZA√á√ÉO:
    Usa chunks de 1MB para balancear mem√≥ria vs. performance
    """
    TAMANHO_CHUNK = 1024 * 1024  # 1 MB por chunk
    
    total_bytes_escritos = 0
    
    try:
        # Abrir arquivo de destino em modo bin√°rio de escrita
        with open(caminho_destino, "wb") as arquivo_destino:
            # Ler e escrever em chunks
            while True:
                chunk = await arquivo_upload.read(TAMANHO_CHUNK)
                if not chunk:
                    # Fim do arquivo
                    break
                arquivo_destino.write(chunk)
                total_bytes_escritos += len(chunk)
        
        logger.info(
            f"Arquivo salvo com sucesso: {caminho_destino} "
            f"({total_bytes_escritos} bytes)"
        )
        
        return total_bytes_escritos
        
    except Exception as erro:
        logger.error(f"Erro ao salvar arquivo {caminho_destino}: {erro}")
        # Tentar deletar arquivo parcialmente escrito
        if caminho_destino.exists():
            caminho_destino.unlink()
        raise


# ===== FUN√á√ÉO DE GERA√á√ÉO DE SHORTCUTS SUGERIDOS =====

def gerar_shortcuts_sugeridos(documentos_aceitos: List[InformacaoDocumentoUploadado]) -> List[str]:
    """
    Gera uma lista de prompts/perguntas sugeridos baseados nos tipos de documentos enviados.
    
    CONTEXTO DE NEG√ìCIO:
    Ap√≥s o upload, queremos orientar o usu√°rio sobre que tipo de an√°lise ele pode solicitar.
    Os shortcuts s√£o prompts pr√©-configurados que facilitam a intera√ß√£o com o sistema multi-agent.
    
    ESTRAT√âGIA:
    - Analisa os tipos de documentos enviados (PDF, DOCX, imagens)
    - Retorna shortcuts contextualizados que fazem sentido para documentos jur√≠dicos
    - Mant√©m uma lista gen√©rica para todos os casos
    - Adiciona shortcuts espec√≠ficos baseados em padr√µes comuns
    
    PROMPTS DISPON√çVEIS:
    - An√°lise de nexo causal (relevante para casos m√©dicos/trabalhistas)
    - Avalia√ß√£o de incapacidade laboral (m√©dico)
    - Investiga√ß√£o de conformidade com NRs (seguran√ßa do trabalho)
    - Caracteriza√ß√£o de insalubridade/periculosidade (seguran√ßa do trabalho)
    - An√°lise de acidente de trabalho (seguran√ßa do trabalho)
    - Resumo jur√≠dico geral (sempre relevante)
    - Identifica√ß√£o de riscos ocupacionais (seguran√ßa do trabalho)
    - Avalia√ß√£o de EPIs (seguran√ßa do trabalho)
    
    IMPLEMENTA√á√ÉO:
    Por ora, retornamos um conjunto fixo de shortcuts mais comuns.
    Futuras melhorias podem incluir:
    - An√°lise do nome do arquivo para detectar contexto (ex: "laudo_medico.pdf")
    - Uso de IA para extrair trechos do documento e sugerir perguntas relevantes
    - Hist√≥rico do usu√°rio (quais prompts ele mais usa)
    
    Args:
        documentos_aceitos: Lista de documentos que foram aceitos no upload
    
    Returns:
        Lista de strings com prompts sugeridos (m√°ximo 6 para n√£o sobrecarregar a UI)
    
    Examples:
        >>> docs = [InformacaoDocumentoUploadado(nome_arquivo_original="laudo.pdf", ...)]
        >>> gerar_shortcuts_sugeridos(docs)
        ["Analisar nexo causal...", "Avaliar grau de incapacidade...", ...]
    """
    
    # Se n√£o houver documentos, retornar lista vazia
    if not documentos_aceitos:
        return []
    
    # Conjunto de shortcuts contextuais comuns em processos trabalhistas/jur√≠dicos
    # NOTA PARA LLMs FUTURAS: Estes prompts foram escolhidos baseados nos agentes dispon√≠veis
    # (Perito M√©dico e Perito Seguran√ßa do Trabalho). Se novos agentes forem adicionados,
    # considere adicionar novos shortcuts relevantes aqui.
    
    shortcuts_disponiveis = [
        "Analisar nexo causal entre doen√ßa e trabalho",
        "Avaliar grau de incapacidade laboral do trabalhador",
        "Investigar conformidade com Normas Regulamentadoras (NRs)",
        "Caracterizar insalubridade ou periculosidade do ambiente",
        "Analisar causas e responsabilidades de acidente de trabalho",
        "Resumir principais pontos jur√≠dicos do processo",
        "Identificar riscos ocupacionais presentes nos documentos",
        "Avaliar adequa√ß√£o e uso de EPIs (Equipamentos de Prote√ß√£o Individual)"
    ]
    
    # Por enquanto, retornamos os 6 primeiros shortcuts (sele√ß√£o fixa)
    # FUTURO: Implementar l√≥gica inteligente para selecionar shortcuts baseados em:
    # - Nome dos arquivos (regex para detectar "laudo", "atestado", "CAT", etc)
    # - Tipo de documento (PDF m√©dico vs. PDF administrativo)
    # - Conte√∫do parcial (primeiras linhas do documento)
    shortcuts_selecionados = shortcuts_disponiveis[:6]
    
    logger.info(f"Gerados {len(shortcuts_selecionados)} shortcuts sugeridos para {len(documentos_aceitos)} documento(s)")
    
    return shortcuts_selecionados


# ===== ENDPOINTS =====

@router.post(
    "/upload",
    response_model=RespostaUploadDocumento,
    status_code=status.HTTP_200_OK,
    summary="Upload de documentos jur√≠dicos",
    description="""
    Faz upload de um ou mais documentos jur√≠dicos para processamento.
    
    **Tipos de arquivo aceitos:**
    - PDF (.pdf): Documentos em formato PDF (texto ou escaneado)
    - DOCX (.docx): Documentos do Microsoft Word
    - Imagens (.png, .jpg, .jpeg): Documentos escaneados
    
    **Valida√ß√µes aplicadas:**
    - Tamanho m√°ximo por arquivo: 50MB (configur√°vel)
    - Apenas extens√µes permitidas
    
    **Fluxo:**
    1. Arquivo √© validado (tipo e tamanho)
    2. UUID √∫nico √© gerado
    3. Arquivo √© salvo em pasta tempor√°ria
    4. Processamento completo √© agendado em background
    5. Metadados s√£o retornados imediatamente
    
    **Processamento em background:**
    Ap√≥s retornar resposta, o sistema processa o documento:
    - Extra√ß√£o de texto (ou OCR)
    - Chunking e vetoriza√ß√£o
    - Armazenamento no ChromaDB
    
    Use o endpoint /status/{documento_id} para acompanhar progresso.
    """
)
async def endpoint_upload_documentos(
    arquivos: List[UploadFile] = File(
        ...,
        description="Lista de arquivos a fazer upload (um ou mais documentos)"
    ),
    background_tasks: BackgroundTasks = BackgroundTasks()
) -> RespostaUploadDocumento:
    """
    Endpoint para upload de documentos jur√≠dicos.
    
    CONTEXTO DE NEG√ìCIO:
    Este √© o ponto de entrada principal do fluxo de ingest√£o de documentos.
    Advogados fazem upload de peti√ß√µes, senten√ßas, laudos periciais, etc.
    
    VALIDA√á√ïES REALIZADAS:
    1. Verificar se pelo menos um arquivo foi enviado
    2. Validar tipo de cada arquivo (extens√£o)
    3. Validar tamanho de cada arquivo
    4. Salvar arquivos v√°lidos em pasta tempor√°ria
    5. Gerar UUID √∫nico para cada arquivo
    
    RETORNO:
    - Sucesso: Lista de documentos aceitos + metadados
    - Falha parcial: Documentos aceitos + lista de erros
    - Falha total: Lista vazia de documentos + lista de erros
    
    Args:
        arquivos: Lista de UploadFile enviados via multipart/form-data
    
    Returns:
        RespostaUploadDocumento com status, metadados e poss√≠veis erros
    
    Raises:
        HTTPException 400: Se nenhum arquivo for enviado
    """
    
    # ===== VALIDA√á√ÉO INICIAL =====
    
    if not arquivos:
        logger.warning("Tentativa de upload sem arquivos")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Nenhum arquivo foi enviado. Por favor, envie pelo menos um documento."
        )
    
    logger.info(f"Recebida requisi√ß√£o de upload com {len(arquivos)} arquivo(s)")
    
    # ===== PREPARA√á√ÉO =====
    
    pasta_uploads = obter_caminho_pasta_uploads_temp()
    
    documentos_aceitos: List[InformacaoDocumentoUploadado] = []
    lista_de_erros: List[str] = []
    
    # ===== PROCESSAMENTO DE CADA ARQUIVO =====
    
    for arquivo in arquivos:
        nome_original = arquivo.filename
        
        logger.info(f"Processando arquivo: {nome_original}")
        
        # VALIDA√á√ÉO 1: Tipo de arquivo
        if not validar_tipo_de_arquivo(nome_original):
            extensao_atual = obter_extensao_do_arquivo(nome_original)
            mensagem_erro = (
                f"Arquivo '{nome_original}' rejeitado: "
                f"tipo '{extensao_atual}' n√£o √© suportado. "
                f"Tipos aceitos: {', '.join(EXTENSOES_PERMITIDAS)}"
            )
            logger.warning(mensagem_erro)
            lista_de_erros.append(mensagem_erro)
            continue  # Pular para o pr√≥ximo arquivo
        
        # Obter extens√£o v√°lida
        extensao = obter_extensao_do_arquivo(nome_original)
        tipo_documento = MAPEAMENTO_EXTENSAO_PARA_TIPO[extensao]
        
        # VALIDA√á√ÉO 2: Tamanho do arquivo
        # Precisamos ler o tamanho do arquivo
        # UploadFile.file √© um SpooledTemporaryFile
        arquivo.file.seek(0, 2)  # Mover para o final do arquivo
        tamanho_bytes = arquivo.file.tell()  # Obter posi√ß√£o (tamanho)
        arquivo.file.seek(0)  # Voltar para o in√≠cio
        
        if not validar_tamanho_de_arquivo(tamanho_bytes):
            tamanho_mb = tamanho_bytes / (1024 * 1024)
            mensagem_erro = (
                f"Arquivo '{nome_original}' rejeitado: "
                f"tamanho {tamanho_mb:.2f}MB excede o limite de "
                f"{configuracoes.TAMANHO_MAXIMO_ARQUIVO_MB}MB"
            )
            logger.warning(mensagem_erro)
            lista_de_erros.append(mensagem_erro)
            continue
        
        # ===== SALVAR ARQUIVO =====
        
        try:
            # Gerar UUID √∫nico e nome de arquivo
            id_documento, nome_arquivo_uuid = gerar_nome_arquivo_unico(extensao)
            
            # Caminho completo onde o arquivo ser√° salvo
            caminho_arquivo = pasta_uploads / nome_arquivo_uuid
            
            # Salvar arquivo no disco
            bytes_escritos = await salvar_arquivo_no_disco(arquivo, caminho_arquivo)
            
            # Criar objeto de informa√ß√£o do documento
            data_hora_atual = datetime.now()
            
            info_documento = InformacaoDocumentoUploadado(
                id_documento=id_documento,
                nome_arquivo_original=nome_original,
                tamanho_em_bytes=bytes_escritos,
                tipo_documento=tipo_documento,
                caminho_temporario=str(caminho_arquivo),
                status_processamento=StatusProcessamentoEnum.PENDENTE,
                data_hora_upload=data_hora_atual
            )
            
            documentos_aceitos.append(info_documento)
            
            # Armazenar informa√ß√µes no cache de status
            documentos_status_cache[id_documento] = {
                "documento_id": id_documento,
                "nome_arquivo_original": nome_original,
                "status": StatusProcessamentoEnum.PENDENTE,
                "data_hora_upload": data_hora_atual,
                "resultado_processamento": None
            }
            
            # Agendar processamento em background
            background_tasks.add_task(
                processar_documento_background,
                caminho_arquivo=str(caminho_arquivo),
                documento_id=id_documento,
                nome_arquivo_original=nome_original,
                tipo_documento=tipo_documento.value,  # Converter enum para string
                data_upload=data_hora_atual.isoformat()  # Passar data de upload em formato ISO
            )
            
            logger.info(
                f"Arquivo '{nome_original}' salvo com sucesso "
                f"(ID: {id_documento}). Processamento agendado."
            )
            
        except Exception as erro:
            mensagem_erro = (
                f"Erro ao salvar arquivo '{nome_original}': {str(erro)}"
            )
            logger.error(mensagem_erro, exc_info=True)
            lista_de_erros.append(mensagem_erro)
            continue
    
    # ===== PREPARAR RESPOSTA =====
    
    total_recebidos = len(arquivos)
    total_aceitos = len(documentos_aceitos)
    total_rejeitados = len(lista_de_erros)
    
    # Determinar se a opera√ß√£o foi bem-sucedida
    # Sucesso = pelo menos um arquivo foi aceito
    sucesso = total_aceitos > 0
    
    # Gerar mensagem apropriada
    if sucesso and total_rejeitados == 0:
        mensagem = (
            f"Upload realizado com sucesso! "
            f"{total_aceitos} arquivo(s) aceito(s) e agendado(s) para processamento. "
            f"Use GET /api/documentos/status/{{documento_id}} para acompanhar o progresso."
        )
    elif sucesso and total_rejeitados > 0:
        mensagem = (
            f"Upload parcialmente conclu√≠do. "
            f"{total_aceitos} arquivo(s) aceito(s) e agendado(s) para processamento, "
            f"{total_rejeitados} rejeitado(s). "
            f"Use GET /api/documentos/status/{{documento_id}} para acompanhar o progresso. "
            f"Veja lista de erros."
        )
    else:
        mensagem = (
            f"Upload falhou. Nenhum arquivo foi aceito. "
            f"{total_rejeitados} arquivo(s) rejeitado(s). Veja lista de erros."
        )
    
    logger.info(
        f"Upload finalizado: {total_aceitos} aceitos, "
        f"{total_rejeitados} rejeitados"
    )
    
    # Gerar shortcuts sugeridos baseados nos documentos aceitos
    shortcuts = gerar_shortcuts_sugeridos(documentos_aceitos)
    
    resposta = RespostaUploadDocumento(
        sucesso=sucesso,
        mensagem=mensagem,
        total_arquivos_recebidos=total_recebidos,
        total_arquivos_aceitos=total_aceitos,
        total_arquivos_rejeitados=total_rejeitados,
        documentos=documentos_aceitos,
        erros=lista_de_erros,
        shortcuts_sugeridos=shortcuts
    )
    
    return resposta


# ===== ENDPOINT DE HEALTH CHECK (BONUS) =====

@router.get(
    "/health",
    summary="Health check do servi√ßo de documentos",
    description="Verifica se o servi√ßo est√° funcionando e se a pasta de uploads est√° acess√≠vel"
)
async def endpoint_health_check() -> dict:
    """
    Endpoint simples para verificar sa√∫de do servi√ßo.
    
    CONTEXTO:
    √ötil para monitoramento e testes de integra√ß√£o.
    Verifica se a pasta de uploads est√° acess√≠vel.
    
    Returns:
        Dict com status e informa√ß√µes do servi√ßo
    """
    try:
        pasta_uploads = obter_caminho_pasta_uploads_temp()
        pasta_acessivel = pasta_uploads.exists() and pasta_uploads.is_dir()
        
        return {
            "status": "healthy",
            "servico": "Upload de Documentos",
            "pasta_uploads_acessivel": pasta_acessivel,
            "caminho_uploads": str(pasta_uploads)
        }
    except Exception as erro:
        logger.error(f"Erro no health check: {erro}")
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Servi√ßo temporariamente indispon√≠vel"
        )


# ===== FUN√á√ïES DE PROCESSAMENTO EM BACKGROUND =====

def processar_documento_background(
    caminho_arquivo: str,
    documento_id: str,
    nome_arquivo_original: str,
    tipo_documento: str,
    data_upload: str = None
) -> None:
    """
    Processa um documento em background (tarefa ass√≠ncrona).
    
    CONTEXTO:
    O processamento de documentos pode levar v√°rios segundos (OCR, vetoriza√ß√£o, etc).
    Para n√£o bloquear a resposta do endpoint de upload, processamos em background.
    
    FLUXO:
    1. Atualizar status para "processando"
    2. Chamar servico_ingestao_documentos.processar_documento_completo()
    3. Atualizar status para "concluido" ou "erro"
    4. Armazenar resultado no cache
    
    Args:
        caminho_arquivo: Caminho do arquivo no disco
        documento_id: UUID do documento
        nome_arquivo_original: Nome original do arquivo
        tipo_documento: Tipo do documento (pdf, docx, etc)
        data_upload: Data e hora do upload em formato ISO
    """
    logger.info(f"[BACKGROUND] Iniciando processamento de {documento_id}")
    
    # Atualizar status para processando
    documentos_status_cache[documento_id]["status"] = StatusProcessamentoEnum.PROCESSANDO
    
    try:
        logger.info(f"[BACKGROUND] Iniciando processamento completo do documento {documento_id}")
        logger.info(f"[BACKGROUND] Arquivo: {caminho_arquivo}")
        logger.info(f"[BACKGROUND] Tipo: {tipo_documento}")
        
        # Processar documento completo
        resultado = servico_ingestao_documentos.processar_documento_completo(
            caminho_arquivo=caminho_arquivo,
            documento_id=documento_id,
            nome_arquivo_original=nome_arquivo_original,
            tipo_documento=tipo_documento,
            data_upload=data_upload
        )
        
        logger.info(f"[BACKGROUND] ‚úÖ Processamento de {documento_id} conclu√≠do com sucesso!")
        logger.info(f"[BACKGROUND] Resultado: {resultado}")
        
        # Atualizar status para conclu√≠do
        documentos_status_cache[documento_id]["status"] = StatusProcessamentoEnum.CONCLUIDO
        documentos_status_cache[documento_id]["resultado_processamento"] = resultado
        
        logger.info(f"[BACKGROUND] Status atualizado para CONCLUIDO: {documento_id}")
    
    except Exception as erro:
        # Atualizar status para erro
        logger.error(f"[BACKGROUND] ‚ùå ERRO ao processar {documento_id}!")
        logger.error(f"[BACKGROUND] Tipo do erro: {type(erro).__name__}")
        logger.error(f"[BACKGROUND] Mensagem: {str(erro)}", exc_info=True)
        
        documentos_status_cache[documento_id]["status"] = StatusProcessamentoEnum.ERRO
        documentos_status_cache[documento_id]["resultado_processamento"] = {
            "sucesso": False,
            "documento_id": documento_id,
            "mensagem_erro": str(erro),
            "tipo_erro": type(erro).__name__
        }
        
        logger.error(f"[BACKGROUND] Status atualizado para ERRO: {documento_id}")


# ===== NOVOS ENDPOINTS =====

@router.get(
    "/status/{documento_id}",
    response_model=StatusDocumento,
    summary="Consultar status de processamento de um documento",
    description="""
    Consulta o status atual de processamento de um documento espec√≠fico.
    
    **Status poss√≠veis:**
    - pendente: Documento aguardando processamento
    - processando: Extra√ß√£o de texto/OCR em andamento
    - concluido: Processamento finalizado com sucesso
    - erro: Falha durante processamento
    
    **Uso:**
    Ap√≥s fazer upload, use este endpoint para acompanhar o progresso
    do processamento do documento.
    """
)
async def endpoint_consultar_status_documento(documento_id: str) -> StatusDocumento:
    """
    Consulta o status de processamento de um documento.
    
    CONTEXTO:
    Ap√≥s upload, frontend pode consultar periodicamente este endpoint
    para saber quando o documento foi processado e est√° dispon√≠vel para consulta.
    
    Args:
        documento_id: UUID do documento
    
    Returns:
        StatusDocumento com informa√ß√µes atuais
    
    Raises:
        HTTPException 404: Se documento n√£o for encontrado
    """
    logger.info(f"Consultando status do documento: {documento_id}")
    
    # Verificar se documento existe no cache
    if documento_id not in documentos_status_cache:
        logger.warning(f"Documento n√£o encontrado: {documento_id}")
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Documento '{documento_id}' n√£o foi encontrado no sistema"
        )
    
    # Obter informa√ß√µes do cache
    info_documento = documentos_status_cache[documento_id]
    
    # Montar resposta
    resposta = StatusDocumento(
        documento_id=documento_id,
        nome_arquivo_original=info_documento["nome_arquivo_original"],
        status=info_documento["status"],
        data_hora_upload=info_documento["data_hora_upload"],
        resultado_processamento=info_documento.get("resultado_processamento")
    )
    
    return resposta


@router.get(
    "/listar",
    response_model=RespostaListarDocumentos,
    summary="Listar todos os documentos processados",
    description="""
    Lista todos os documentos que foram processados e est√£o dispon√≠veis
    no sistema RAG (ChromaDB).
    
    **Retorna:**
    - Total de documentos
    - Lista com metadados de cada documento
    """
)
async def endpoint_listar_documentos() -> RespostaListarDocumentos:
    """
    Lista todos os documentos dispon√≠veis no sistema.
    
    CONTEXTO:
    √ötil para visualizar todos os documentos que foram processados
    e est√£o dispon√≠veis para consulta pelos agentes de IA.
    
    IMPLEMENTA√á√ÉO:
    Consulta diretamente o ChromaDB para obter lista de documentos √∫nicos.
    
    Returns:
        RespostaListarDocumentos com lista de documentos
    """
    logger.info("Listando todos os documentos do sistema")
    
    try:
        # Inicializar ChromaDB
        _, collection = servico_banco_vetorial.inicializar_chromadb()
        
        # Obter lista de documentos do ChromaDB
        documentos_chromadb = servico_banco_vetorial.listar_documentos(collection)
        
        # Transformar para formato esperado pelo frontend (camelCase)
        documentos_formatados = []
        for doc in documentos_chromadb:
            doc_formatado = {
                "idDocumento": doc.get("documento_id", ""),
                "nomeArquivo": doc.get("nome_arquivo", "Desconhecido"),
                "tipoDocumento": doc.get("tipo_documento", "pdf"),
                "tamanhoEmBytes": 0,  # ChromaDB n√£o armazena tamanho
                "dataHoraUpload": doc.get("data_upload", ""),
                "statusProcessamento": "concluido",  # Se est√° no ChromaDB, foi processado
                "numeroChunks": doc.get("numero_chunks", 0)
            }
            documentos_formatados.append(doc_formatado)
        
        logger.info(f"Encontrados {len(documentos_formatados)} documentos no sistema")
        
        resposta = RespostaListarDocumentos(
            sucesso=True,
            total_documentos=len(documentos_formatados),
            documentos=documentos_formatados
        )
        
        return resposta
    
    except Exception as erro:
        logger.error(f"Erro ao listar documentos: {erro}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao listar documentos: {str(erro)}"
        )


@router.delete(
    "/{documento_id}",
    response_model=RespostaDeletarDocumento,
    summary="Deletar documento",
    description="""
    Deleta um documento espec√≠fico do sistema.
    
    **Opera√ß√£o realizada:**
    1. Remove todos os chunks do ChromaDB (banco vetorial)
    2. Remove o arquivo f√≠sico do disco (uploads_temp/)
    3. Remove o documento do cache de status
    
    **ATEN√á√ÉO:** Esta opera√ß√£o √© IRREVERS√çVEL.
    
    **Retorna:**
    - Confirma√ß√£o de dele√ß√£o
    - N√∫mero de chunks removidos
    - Informa√ß√µes do documento deletado
    """,
    responses={
        200: {
            "description": "Documento deletado com sucesso",
            "model": RespostaDeletarDocumento
        },
        404: {
            "description": "Documento n√£o encontrado",
            "model": RespostaErro
        },
        500: {
            "description": "Erro ao deletar documento",
            "model": RespostaErro
        }
    }
)
async def endpoint_deletar_documento(documento_id: str) -> RespostaDeletarDocumento:
    """
    Deleta um documento do sistema.
    
    CONTEXTO:
    Permite ao usu√°rio remover documentos que n√£o s√£o mais necess√°rios
    ou foram enviados por engano. A dele√ß√£o √© completa: remove do banco
    vetorial, do disco e do cache.
    
    IMPLEMENTA√á√ÉO:
    1. Valida se documento existe no ChromaDB
    2. Remove chunks do ChromaDB
    3. Tenta remover arquivo f√≠sico (se existir)
    4. Remove do cache de status
    5. Retorna confirma√ß√£o com n√∫mero de chunks removidos
    
    Args:
        documento_id: UUID do documento a ser deletado
    
    Returns:
        RespostaDeletarDocumento com confirma√ß√£o da opera√ß√£o
    
    Raises:
        HTTPException 404: Se documento n√£o for encontrado
        HTTPException 500: Se erro durante dele√ß√£o
    """
    logger.info(f"üóëÔ∏è Requisi√ß√£o para deletar documento: {documento_id}")
    
    try:
        # Obter collection do ChromaDB
        cliente_chroma, collection = servico_banco_vetorial.inicializar_chromadb()
        
        # Antes de deletar, buscar informa√ß√µes do documento
        documento_info = None
        chunks_removidos = 0
        
        # Tentar obter informa√ß√µes do documento antes de deletar
        try:
            resultados = collection.get(
                where={"documento_id": documento_id},
                include=["metadatas"],
                limit=1
            )
            
            if resultados["ids"] and len(resultados["ids"]) > 0:
                metadados = resultados["metadatas"][0]
                documento_info = {
                    "nome_arquivo": metadados.get("nome_arquivo", "desconhecido"),
                }
                
                # Contar total de chunks antes de deletar
                todos_chunks = collection.get(
                    where={"documento_id": documento_id},
                    include=[]
                )
                chunks_removidos = len(todos_chunks["ids"])
        except Exception as erro_busca:
            logger.warning(f"N√£o foi poss√≠vel obter informa√ß√µes do documento antes de deletar: {erro_busca}")
        
        # Deletar documento do ChromaDB
        documento_deletado = servico_banco_vetorial.deletar_documento(
            collection=collection,
            documento_id=documento_id
        )
        
        if not documento_deletado:
            logger.warning(f"‚ö†Ô∏è Documento {documento_id} n√£o encontrado no ChromaDB")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Documento {documento_id} n√£o encontrado no sistema"
            )
        
        # Tentar remover arquivo f√≠sico (se existir)
        # Procurar em uploads_temp/ por arquivo com esse UUID
        pasta_uploads = Path(configuracoes.CAMINHO_UPLOADS_TEMP)
        arquivo_deletado = False
        
        for extensao in EXTENSOES_PERMITIDAS:
            caminho_arquivo = pasta_uploads / f"{documento_id}{extensao}"
            if caminho_arquivo.exists():
                try:
                    caminho_arquivo.unlink()  # Deleta arquivo
                    arquivo_deletado = True
                    logger.info(f"‚úÖ Arquivo f√≠sico deletado: {caminho_arquivo}")
                    break
                except Exception as erro_arquivo:
                    logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel deletar arquivo f√≠sico: {erro_arquivo}")
        
        if not arquivo_deletado:
            logger.warning(f"‚ö†Ô∏è Arquivo f√≠sico do documento {documento_id} n√£o foi encontrado")
        
        # Remover do cache de status (se existir)
        if documento_id in documentos_status_cache:
            del documentos_status_cache[documento_id]
            logger.info(f"‚úÖ Documento removido do cache de status")
        
        # Preparar resposta
        nome_arquivo = documento_info["nome_arquivo"] if documento_info else "desconhecido"
        
        resposta = RespostaDeletarDocumento(
            sucesso=True,
            mensagem=f"Documento '{nome_arquivo}' deletado com sucesso",
            documento_id=documento_id,
            nome_arquivo=nome_arquivo,
            chunks_removidos=chunks_removidos
        )
        
        logger.info(
            f"‚úÖ Documento deletado com sucesso: {documento_id} "
            f"({chunks_removidos} chunks removidos)"
        )
        
        return resposta
    
    except HTTPException:
        # Re-raise HTTPException (404, etc)
        raise
    
    except Exception as erro:
        logger.error(f"‚ùå Erro ao deletar documento {documento_id}: {erro}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao deletar documento: {str(erro)}"
        )


# ===== ENDPOINTS DE UPLOAD ASS√çNCRONO (TAREFA-036) =====

@router.post(
    "/iniciar-upload",
    response_model=RespostaIniciarUpload,
    status_code=status.HTTP_202_ACCEPTED,
    summary="Iniciar upload ass√≠ncrono de documento",
    description="""
    Inicia o processamento ass√≠ncrono de upload de um documento.
    
    **DIFEREN√áA DO ENDPOINT S√çNCRONO (/upload):**
    - Este endpoint retorna IMEDIATAMENTE (<100ms) com um upload_id
    - O processamento ocorre em background (sem bloquear a requisi√ß√£o)
    - Cliente usa upload_id para fazer polling do progresso
    
    **BENEF√çCIOS:**
    - Zero timeouts HTTP (mesmo para arquivos grandes ou OCR demorado)
    - Suporte a m√∫ltiplos uploads simult√¢neos
    - Feedback de progresso em tempo real (0-100%)
    - UI responsiva (n√£o trava durante upload)
    
    **FLUXO:**
    1. Cliente faz POST /iniciar-upload com arquivo
    2. Backend valida tipo e tamanho
    3. Backend salva arquivo temporariamente
    4. Backend gera upload_id (UUID)
    5. Backend agenda processamento em background
    6. Backend retorna upload_id IMEDIATAMENTE (202 Accepted)
    7. Cliente usa GET /status-upload/{upload_id} para acompanhar progresso
    8. Quando status = CONCLUIDO, cliente usa GET /resultado-upload/{upload_id}
    
    **Tipos de arquivo aceitos:**
    - PDF (.pdf): Documentos em formato PDF (texto ou escaneado)
    - DOCX (.docx): Documentos do Microsoft Word
    - Imagens (.png, .jpg, .jpeg): Documentos escaneados
    
    **Valida√ß√µes aplicadas:**
    - Tamanho m√°ximo: 50MB (configur√°vel)
    - Apenas extens√µes permitidas
    
    **Etapas de Processamento (acompanhe via polling):**
    1. Salvando arquivo (0-10%)
    2. Detectando tipo (10-15%)
    3. Extraindo texto (15-30%)
    4. OCR se necess√°rio (30-60%)
    5. Chunking (60-70%)
    6. Gerando embeddings (70-90%)
    7. Salvando no ChromaDB (90-100%)
    """
)
async def endpoint_iniciar_upload_assincrono(
    arquivo: UploadFile = File(
        ...,
        description="Arquivo a fazer upload (um documento por requisi√ß√£o)"
    ),
    background_tasks: BackgroundTasks = BackgroundTasks()
) -> RespostaIniciarUpload:
    """
    Endpoint para iniciar upload ass√≠ncrono de documento.
    
    CONTEXTO DE NEG√ìCIO (TAREFA-036):
    Este endpoint implementa o padr√£o ass√≠ncrono de upload, similar ao padr√£o
    implementado para an√°lise multi-agent (TAREFAS 030-034). Elimina timeouts
    HTTP e permite feedback de progresso em tempo real.
    
    PADR√ÉO ASS√çNCRONO:
    1. Validar arquivo (tipo e tamanho)
    2. Salvar arquivo temporariamente
    3. Gerar upload_id (UUID)
    4. Criar registro no GerenciadorEstadoUploads (status: INICIADO)
    5. Agendar processamento em background via BackgroundTasks
    6. Retornar upload_id imediatamente (202 Accepted)
    
    PROCESSAMENTO EM BACKGROUND:
    - Fun√ß√£o: servico_ingestao_documentos.processar_documento_em_background()
    - Reporta progresso via GerenciadorEstadoUploads
    - 7 micro-etapas de progresso (0-100%)
    - Trata erros e atualiza status para ERRO se falhar
    
    Args:
        arquivo: UploadFile enviado via multipart/form-data
        background_tasks: FastAPI BackgroundTasks para processamento ass√≠ncrono
    
    Returns:
        RespostaIniciarUpload com upload_id e status INICIADO
    
    Raises:
        HTTPException 400: Se nenhum arquivo for enviado ou valida√ß√£o falhar
        HTTPException 413: Se arquivo exceder tamanho m√°ximo
        HTTPException 415: Se tipo de arquivo n√£o for suportado
    """
    
    # ===== VALIDA√á√ÉO INICIAL =====
    
    if not arquivo or not arquivo.filename:
        logger.warning("Tentativa de upload sem arquivo")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Nenhum arquivo foi enviado. Por favor, envie um documento."
        )
    
    nome_original = arquivo.filename
    logger.info(f"[UPLOAD ASS√çNCRONO] Recebida requisi√ß√£o de upload: {nome_original}")
    
    # ===== VALIDA√á√ÉO DE TIPO =====
    
    if not validar_tipo_de_arquivo(nome_original):
        extensao_atual = obter_extensao_do_arquivo(nome_original)
        mensagem_erro = (
            f"Tipo de arquivo '{extensao_atual}' n√£o √© suportado. "
            f"Tipos aceitos: {', '.join(EXTENSOES_PERMITIDAS)}"
        )
        logger.warning(f"[UPLOAD ASS√çNCRONO] {mensagem_erro}")
        raise HTTPException(
            status_code=status.HTTP_415_UNSUPPORTED_MEDIA_TYPE,
            detail=mensagem_erro
        )
    
    extensao = obter_extensao_do_arquivo(nome_original)
    tipo_documento = MAPEAMENTO_EXTENSAO_PARA_TIPO[extensao]
    
    # ===== VALIDA√á√ÉO DE TAMANHO =====
    
    # UploadFile.file √© um SpooledTemporaryFile
    arquivo.file.seek(0, 2)  # Mover para o final do arquivo
    tamanho_bytes = arquivo.file.tell()  # Obter posi√ß√£o (tamanho)
    arquivo.file.seek(0)  # Voltar para o in√≠cio
    
    if not validar_tamanho_de_arquivo(tamanho_bytes):
        tamanho_mb = tamanho_bytes / (1024 * 1024)
        mensagem_erro = (
            f"Arquivo muito grande ({tamanho_mb:.2f}MB). "
            f"Tamanho m√°ximo permitido: {configuracoes.TAMANHO_MAXIMO_ARQUIVO_MB}MB"
        )
        logger.warning(f"[UPLOAD ASS√çNCRONO] {mensagem_erro}")
        raise HTTPException(
            status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
            detail=mensagem_erro
        )
    
    # ===== GERAR IDS √öNICOS =====
    
    # upload_id: UUID para rastrear progresso do upload
    upload_id = str(uuid.uuid4())
    
    # documento_id: UUID do documento (ser√° usado no ChromaDB)
    documento_id = str(uuid.uuid4())
    
    logger.info(
        f"[UPLOAD ASS√çNCRONO] Upload iniciado - upload_id: {upload_id}, "
        f"documento_id: {documento_id}, arquivo: {nome_original}"
    )
    
    # ===== SALVAR ARQUIVO TEMPORARIAMENTE =====
    
    try:
        pasta_uploads = obter_caminho_pasta_uploads_temp()
        
        # Nome do arquivo: {documento_id}{extensao}
        nome_arquivo_uuid = f"{documento_id}{extensao}"
        caminho_arquivo = pasta_uploads / nome_arquivo_uuid
        
        # Salvar arquivo no disco
        bytes_escritos = await salvar_arquivo_no_disco(arquivo, caminho_arquivo)
        
        logger.info(
            f"[UPLOAD ASS√çNCRONO] Arquivo salvo temporariamente: {caminho_arquivo} "
            f"({bytes_escritos} bytes)"
        )
        
    except Exception as erro:
        mensagem_erro = f"Erro ao salvar arquivo: {str(erro)}"
        logger.error(f"[UPLOAD ASS√çNCRONO] {mensagem_erro}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=mensagem_erro
        )
    
    # ===== CRIAR REGISTRO NO GERENCIADOR DE ESTADO =====
    
    try:
        gerenciador = obter_gerenciador_estado_uploads()
        
        # Criar upload com status INICIADO e progresso 0%
        gerenciador.criar_upload(
            upload_id=upload_id,
            nome_arquivo=nome_original,
            tamanho_bytes=tamanho_bytes,
            tipo_documento=tipo_documento.value,
            documento_id=documento_id
        )
        
        logger.info(
            f"[UPLOAD ASS√çNCRONO] Registro criado no gerenciador: "
            f"upload_id={upload_id}, status=INICIADO"
        )
        
    except ValueError as erro:
        # upload_id duplicado (improv√°vel, mas poss√≠vel)
        mensagem_erro = f"Erro ao criar registro de upload: {str(erro)}"
        logger.error(f"[UPLOAD ASS√çNCRONO] {mensagem_erro}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=mensagem_erro
        )
    
    # ===== AGENDAR PROCESSAMENTO EM BACKGROUND =====
    
    # Data de upload atual
    data_hora_atual = datetime.now()
    data_upload_iso = data_hora_atual.isoformat()
    
    background_tasks.add_task(
        servico_ingestao_documentos.processar_documento_em_background,
        upload_id=upload_id,
        caminho_arquivo=str(caminho_arquivo),
        documento_id=documento_id,
        nome_arquivo_original=nome_original,
        tipo_documento=tipo_documento.value,
        data_upload=data_upload_iso
    )
    
    logger.info(
        f"[UPLOAD ASS√çNCRONO] Processamento agendado em background para "
        f"upload_id={upload_id}"
    )
    
    # ===== PREPARAR RESPOSTA =====
    
    resposta = RespostaIniciarUpload(
        upload_id=upload_id,
        status="INICIADO",
        nome_arquivo=nome_original,
        tamanho_bytes=tamanho_bytes,
        timestamp_criacao=data_upload_iso
    )
    
    logger.info(
        f"[UPLOAD ASS√çNCRONO] Upload iniciado com sucesso - "
        f"retornando upload_id={upload_id} ao cliente"
    )
    
    return resposta


@router.get(
    "/status-upload/{upload_id}",
    response_model=RespostaStatusUpload,
    status_code=status.HTTP_200_OK,
    summary="Consultar status de upload ass√≠ncrono",
    description="""
    Consulta o status e progresso de um upload em processamento.
    
    **POLLING:**
    - Frontend deve chamar este endpoint repetidamente (a cada 2s)
    - Continua at√© status = CONCLUIDO ou ERRO
    - Exibe barra de progresso e etapa atual em tempo real
    
    **ESTADOS POSS√çVEIS:**
    - INICIADO: Upload criado, aguardando processamento (0%)
    - SALVANDO: Salvando arquivo no disco (0-10%)
    - PROCESSANDO: Processamento em andamento (10-100%)
    - CONCLUIDO: Processamento finalizado com sucesso (100%)
    - ERRO: Falha durante processamento
    
    **EXEMPLO DE PROGRESS√ÉO:**
    1. status=INICIADO, progresso=0%, etapa="Aguardando processamento"
    2. status=SALVANDO, progresso=10%, etapa="Salvando arquivo no servidor"
    3. status=PROCESSANDO, progresso=20%, etapa="Extraindo texto do PDF"
    4. status=PROCESSANDO, progresso=45%, etapa="Executando OCR"
    5. status=PROCESSANDO, progresso=70%, etapa="Dividindo em chunks"
    6. status=PROCESSANDO, progresso=90%, etapa="Gerando embeddings"
    7. status=CONCLUIDO, progresso=100%, etapa="Processamento conclu√≠do"
    
    **Quando status = CONCLUIDO:**
    - Pare o polling
    - Chame GET /resultado-upload/{upload_id} para obter informa√ß√µes completas
    
    **Quando status = ERRO:**
    - Pare o polling
    - Exiba mensagem_erro ao usu√°rio
    """
)
async def endpoint_status_upload_assincrono(
    upload_id: str
) -> RespostaStatusUpload:
    """
    Endpoint para consultar status de upload ass√≠ncrono (polling).
    
    CONTEXTO DE NEG√ìCIO (TAREFA-036):
    Este endpoint √© chamado repetidamente pelo frontend para acompanhar
    o progresso de um upload em processamento. Fornece feedback em tempo
    real sobre qual etapa est√° sendo executada e o progresso percentual.
    
    PADR√ÉO DE POLLING:
    - Frontend chama a cada 2 segundos
    - Atualiza barra de progresso (0-100%)
    - Exibe etapa atual (ex: "Executando OCR - 45%")
    - Para quando status = CONCLUIDO ou ERRO
    
    CONSULTA:
    1. Buscar upload no GerenciadorEstadoUploads
    2. Extrair status, etapa_atual, progresso_percentual
    3. Retornar informa√ß√µes ao cliente
    
    Args:
        upload_id: UUID do upload (fornecido em POST /iniciar-upload)
    
    Returns:
        RespostaStatusUpload com status, etapa, progresso, timestamp
    
    Raises:
        HTTPException 404: Se upload_id n√£o existir
    """
    
    logger.info(f"[POLLING] Consultando status de upload: {upload_id}")
    
    # ===== BUSCAR UPLOAD NO GERENCIADOR =====
    
    gerenciador = obter_gerenciador_estado_uploads()
    upload = gerenciador.obter_upload(upload_id)
    
    if upload is None:
        logger.warning(f"[POLLING] Upload n√£o encontrado: {upload_id}")
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Upload {upload_id} n√£o encontrado. Verifique se o upload_id est√° correto."
        )
    
    # ===== PREPARAR RESPOSTA =====
    
    resposta = RespostaStatusUpload(
        upload_id=upload.upload_id,
        status=upload.status,
        etapa_atual=upload.etapa_atual,
        progresso_percentual=upload.progresso_percentual,
        timestamp_atualizacao=upload.timestamp_atualizacao,
        mensagem_erro=upload.mensagem_erro
    )
    
    logger.debug(
        f"[POLLING] Status: {upload.status}, "
        f"Progresso: {upload.progresso_percentual}%, "
        f"Etapa: {upload.etapa_atual}"
    )
    
    return resposta


@router.get(
    "/resultado-upload/{upload_id}",
    response_model=RespostaResultadoUpload,
    status_code=status.HTTP_200_OK,
    summary="Obter resultado de upload conclu√≠do",
    description="""
    Obt√©m as informa√ß√µes completas de um documento ap√≥s upload conclu√≠do.
    
    **IMPORTANTE:**
    - S√≥ chame este endpoint quando status = CONCLUIDO
    - Se status ainda for PROCESSANDO ‚Üí Retorna erro 425 (Too Early)
    - Se status for ERRO ‚Üí Retorna erro 500 com mensagem
    
    **RETORNA:**
    - ID do documento no sistema (para usar em an√°lises)
    - Nome original do arquivo
    - Tamanho em bytes
    - Tipo de documento (pdf, docx, etc.)
    - N√∫mero de chunks criados
    - Tempo total de processamento
    - Timestamps de in√≠cio e fim
    
    **USO:**
    Frontend pode:
    - Adicionar documento √† lista de documentos dispon√≠veis
    - Habilitar bot√µes de an√°lise (agora que h√° documentos no RAG)
    - Mostrar confirma√ß√£o de sucesso ao usu√°rio
    """
)
async def endpoint_resultado_upload_assincrono(
    upload_id: str
) -> RespostaResultadoUpload:
    """
    Endpoint para obter resultado de upload ass√≠ncrono conclu√≠do.
    
    CONTEXTO DE NEG√ìCIO (TAREFA-036):
    Quando o polling detecta status = CONCLUIDO, o frontend chama este
    endpoint para obter as informa√ß√µes completas do documento processado.
    
    VALIDA√á√ïES:
    - Se upload n√£o existir ‚Üí 404
    - Se status = PROCESSANDO ‚Üí 425 Too Early (ainda n√£o conclu√≠do)
    - Se status = ERRO ‚Üí 500 com mensagem de erro
    - Se status = CONCLUIDO ‚Üí Retorna informa√ß√µes completas
    
    Args:
        upload_id: UUID do upload (fornecido em POST /iniciar-upload)
    
    Returns:
        RespostaResultadoUpload com informa√ß√µes completas do documento
    
    Raises:
        HTTPException 404: Se upload_id n√£o existir
        HTTPException 425: Se upload ainda n√£o foi conclu√≠do
        HTTPException 500: Se upload falhou com erro
    """
    
    logger.info(f"[RESULTADO] Consultando resultado de upload: {upload_id}")
    
    # ===== BUSCAR UPLOAD NO GERENCIADOR =====
    
    gerenciador = obter_gerenciador_estado_uploads()
    upload = gerenciador.obter_upload(upload_id)
    
    if upload is None:
        logger.warning(f"[RESULTADO] Upload n√£o encontrado: {upload_id}")
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Upload {upload_id} n√£o encontrado. Verifique se o upload_id est√° correto."
        )
    
    # ===== VALIDAR STATUS =====
    
    if upload.status in ["INICIADO", "SALVANDO", "PROCESSANDO"]:
        logger.warning(
            f"[RESULTADO] Upload ainda em processamento: {upload_id} "
            f"(status={upload.status}, progresso={upload.progresso_percentual}%)"
        )
        raise HTTPException(
            status_code=status.HTTP_425_TOO_EARLY,
            detail=(
                f"Upload ainda n√£o foi conclu√≠do. "
                f"Status atual: {upload.status} ({upload.progresso_percentual}%). "
                f"Continue fazendo polling em /status-upload/{upload_id}"
            )
        )
    
    if upload.status == "ERRO":
        logger.error(
            f"[RESULTADO] Upload falhou com erro: {upload_id} - "
            f"{upload.mensagem_erro}"
        )
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Upload falhou: {upload.mensagem_erro}"
        )
    
    # ===== STATUS = CONCLUIDO ‚Üí EXTRAIR RESULTADO =====
    
    if upload.resultado is None:
        logger.error(
            f"[RESULTADO] Upload marcado como CONCLUIDO mas sem resultado: {upload_id}"
        )
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Erro interno: upload conclu√≠do mas sem resultado dispon√≠vel"
        )
    
    resultado = upload.resultado
    
    # Calcular tempo de processamento
    from datetime import datetime
    try:
        tempo_inicio = datetime.fromisoformat(upload.timestamp_criacao)
        tempo_fim = datetime.fromisoformat(upload.timestamp_atualizacao)
        tempo_processamento = (tempo_fim - tempo_inicio).total_seconds()
    except Exception as erro:
        logger.warning(f"Erro ao calcular tempo de processamento: {erro}")
        tempo_processamento = 0.0
    
    # ===== PREPARAR RESPOSTA =====
    
    resposta = RespostaResultadoUpload(
        sucesso=True,
        upload_id=upload.upload_id,
        status=upload.status,
        documento_id=resultado.get("documento_id", "desconhecido"),
        nome_arquivo=upload.nome_arquivo,
        tamanho_bytes=upload.tamanho_bytes,
        tipo_documento=upload.tipo_documento,
        numero_chunks=resultado.get("numero_chunks", 0),
        timestamp_inicio=upload.timestamp_criacao,
        timestamp_fim=upload.timestamp_atualizacao,
        tempo_processamento_segundos=tempo_processamento
    )
    
    logger.info(
        f"[RESULTADO] Upload conclu√≠do com sucesso - "
        f"documento_id={resultado.get('documento_id')}, "
        f"chunks={resultado.get('numero_chunks')}, "
        f"tempo={tempo_processamento:.2f}s"
    )
    
    return resposta


# ===== ENDPOINT DE DEBUG =====

@router.get(
    "/debug/status-cache",
    summary="[DEBUG] Visualizar cache de status de processamento",
    description="""
    **ENDPOINT DE DEBUG**
    
    Retorna o conte√∫do completo do cache de status de documentos.
    √ötil para depura√ß√£o quando documentos n√£o aparecem no frontend.
    
    **Retorna:**
    - Total de documentos no cache
    - Status de cada documento
    - Erros de processamento (se houver)
    """
)
async def endpoint_debug_status_cache() -> dict:
    """
    Retorna o cache completo de status de documentos (para debug).
    
    CONTEXTO:
    Quando um documento n√£o aparece no frontend ap√≥s upload,
    este endpoint permite verificar se o processamento falhou e qual foi o erro.
    """
    logger.info("üìä Consultando cache de status para debug")
    
    return {
        "total_documentos_em_cache": len(documentos_status_cache),
        "documentos": documentos_status_cache
    }

