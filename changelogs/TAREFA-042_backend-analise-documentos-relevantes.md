# TAREFA-042: Backend - Servi√ßo de An√°lise de Documentos Relevantes

**Data de Conclus√£o:** 2025-10-25  
**Respons√°vel:** GitHub Copilot (IA)  
**Status:** ‚úÖ CONCLU√çDA  
**Prioridade:** üî¥ CR√çTICA

---

## üìã RESUMO EXECUTIVO

Implementado servi√ßo de an√°lise autom√°tica de peti√ß√µes iniciais usando LLM (GPT-4) para sugerir documentos relevantes necess√°rios para an√°lise jur√≠dica completa. Este √© o segundo passo do fluxo de an√°lise de peti√ß√£o inicial (FASE 7). O servi√ßo integra ChromaDB para RAG, LLM para an√°lise inteligente e gerenciador de estado de peti√ß√µes para rastreamento.

**Resultado:**
- ‚úÖ Novo servi√ßo: `ServicosAnaliseDocumentosRelevantes` (860 linhas)
- ‚úÖ Nova fun√ß√£o utilit√°ria em `servico_banco_vetorial.py`: `obter_documento_por_id` (110 linhas)
- ‚úÖ Novo endpoint: `POST /api/peticoes/{peticao_id}/analisar-documentos` (200 linhas)
- ‚úÖ Processamento ass√≠ncrono em background (n√£o bloqueia request)
- ‚úÖ Prompt engineering robusto com formato JSON estruturado
- ‚úÖ Tratamento completo de erros da LLM
- ‚úÖ Documenta√ß√£o completa em `ARQUITETURA.md`

---

## üéØ OBJETIVOS DA TAREFA

### Objetivo Principal
Criar servi√ßo que analisa peti√ß√£o inicial usando LLM e sugere documentos relevantes, integrando ChromaDB para RAG e gerenciador de estado de peti√ß√µes.

### Objetivos Espec√≠ficos
1. ‚úÖ Criar classe `ServicoAnaliseDocumentosRelevantes`
2. ‚úÖ Implementar recupera√ß√£o de texto da peti√ß√£o do ChromaDB
3. ‚úÖ Implementar busca RAG para contexto adicional
4. ‚úÖ Criar prompt engineering para sugest√£o de documentos
5. ‚úÖ Implementar parsing de resposta JSON da LLM
6. ‚úÖ Criar fun√ß√£o `obter_documento_por_id` no servi√ßo de banco vetorial
7. ‚úÖ Criar endpoint `POST /api/peticoes/{peticao_id}/analisar-documentos`
8. ‚úÖ Implementar processamento ass√≠ncrono em background
9. ‚úÖ Atualizar `ARQUITETURA.md` com documenta√ß√£o completa

---

## üîß ARQUIVOS CRIADOS/MODIFICADOS

### 1. `backend/src/servicos/servico_analise_documentos_relevantes.py` (CRIADO - 860 linhas)

**Novo m√≥dulo criado:** Servi√ßo completo para an√°lise de peti√ß√µes e sugest√£o de documentos.

#### Exce√ß√µes Customizadas (4 classes):

1. **`ErroAnaliseDocumentosRelevantes`** - Exce√ß√£o base para erros de an√°lise
2. **`ErroPeticaoNaoEncontrada`** - Peti√ß√£o n√£o existe no gerenciador
3. **`ErroDocumentoPeticaoNaoEncontrado`** - Documento n√£o existe no ChromaDB
4. **`ErroParsingRespostaLLM`** - Erro ao parsear JSON da LLM

#### Constantes de Configura√ß√£o:

- `NUMERO_DE_CHUNKS_RAG_PARA_CONTEXTO = 5`: Quantos chunks buscar no RAG
- `MODELO_LLM_ANALISE_DOCUMENTOS = "gpt-4"`: Modelo para an√°lise (melhor racioc√≠nio jur√≠dico)
- `TEMPERATURA_LLM_ANALISE_DOCUMENTOS = 0.3`: Baixa criatividade, respostas factuais
- `TIMEOUT_LLM_SEGUNDOS = 60`: Timeout da chamada LLM

#### Prompt Engineering:

**`PROMPT_SISTEMA_ANALISE_DOCUMENTOS`** (200 linhas):
- Define papel da LLM: "assistente jur√≠dico especializado"
- Explica tarefa: identificar documentos relevantes
- Especifica formato JSON EXATO da resposta
- Define prioridades: essencial, importante, desejavel
- Fornece regras claras (m√≠nimo 3, m√°ximo 15 documentos)

**`construir_prompt_analise_peticao()`**:
- Combina texto da peti√ß√£o + contexto RAG
- Trunca texto para n√£o exceder limite de tokens (8000 caracteres)
- Formata contexto RAG em lista numerada
- Retorna prompt completo para enviar √† LLM

#### Classe Principal: `ServicoAnaliseDocumentosRelevantes`

**M√©todo `__init__()`**:
- Inicializa `GerenciadorLLM` para chamadas OpenAI
- Inicializa ChromaDB para busca RAG
- Obt√©m gerenciador de estado de peti√ß√µes

**M√©todo `analisar_peticao_e_sugerir_documentos(peticao_id)`** (fun√ß√£o principal):
Executa an√°lise em 6 etapas:
1. Validar exist√™ncia da peti√ß√£o
2. Recuperar texto da peti√ß√£o do ChromaDB
3. Fazer busca RAG para contexto adicional
4. Chamar LLM com prompt especializado
5. Parsear resposta JSON em lista de `DocumentoSugerido`
6. Atualizar peti√ß√£o com documentos sugeridos

**M√©todos Auxiliares Privados:**

1. `_validar_e_obter_peticao()`: Valida que peti√ß√£o existe
2. `_recuperar_texto_peticao_do_chromadb()`: Busca chunks da peti√ß√£o e junta em texto √∫nico
3. `_obter_contexto_rag_da_peticao()`: Busca RAG com chunks similares
4. `_chamar_llm_para_sugestao_documentos()`: Chama GPT-4 com prompt
5. `_parsear_resposta_llm_em_documentos()`: Converte JSON em objetos Pydantic
6. `_atualizar_peticao_com_documentos_sugeridos()`: Salva resultado no estado

**Valida√ß√µes Implementadas:**
- Peti√ß√£o existe no gerenciador
- Documento da peti√ß√£o existe no ChromaDB
- Resposta da LLM √© JSON v√°lido
- JSON tem estrutura esperada (campo `documentos_sugeridos`)
- Cada documento tem campos obrigat√≥rios (tipo, justificativa, prioridade)
- Prioridade √© um dos valores v√°lidos (essencial, importante, desejavel)

**Tratamento de Erros:**
- Busca RAG falha ‚Üí Continua sem contexto adicional (n√£o √© cr√≠tico)
- LLM retorna JSON inv√°lido ‚Üí Lan√ßa `ErroParsingRespostaLLM`
- Documento individual inv√°lido ‚Üí Log warning, continua com pr√≥ximos
- Se TODOS documentos inv√°lidos ‚Üí Lan√ßa `ErroParsingRespostaLLM`

#### Fun√ß√£o Utilit√°ria:

**`obter_servico_analise_documentos()`**:
- Factory function para dependency injection
- Retorna inst√¢ncia nova do servi√ßo
- Facilita uso em endpoints FastAPI

---

### 2. `backend/src/servicos/servico_banco_vetorial.py` (MODIFICADO - +110 linhas)

#### Nova Fun√ß√£o: `obter_documento_por_id(collection, documento_id)`

**Responsabilidade:** Recuperar todos os chunks de um documento espec√≠fico pelo ID.

**Implementa√ß√£o:**
1. Busca chunks no ChromaDB filtrando por `where={"documento_id": documento_id}`
2. Ordena chunks por `chunk_index` para manter ordem original
3. Retorna estrutura com documents, metadatas, ids, count

**Returns:**
```python
{
    "documents": ["texto chunk 1", "texto chunk 2", ...],  # Ordenados
    "metadatas": [{...}, {...}, ...],
    "ids": ["id1", "id2", ...],
    "count": 5
}
```

**Caso Especial:** Se documento n√£o encontrado, retorna estrutura vazia:
```python
{
    "documents": [],
    "metadatas": [],
    "ids": [],
    "count": 0
}
```

**Uso no Servi√ßo de An√°lise:**
```python
resultado = obter_documento_por_id(collection, peticao.documento_peticao_id)
chunks = resultado["documents"]
texto_completo = "\n\n".join(chunks)
```

**Justificativa:** Fun√ß√£o necess√°ria para recuperar texto completo da peti√ß√£o durante an√°lise.

---

### 3. `backend/src/api/rotas_peticoes.py` (MODIFICADO - +200 linhas)

#### Imports Adicionados:

```python
from src.servicos.servico_analise_documentos_relevantes import (
    obter_servico_analise_documentos,
    ErroAnaliseDocumentosRelevantes,
    ErroPeticaoNaoEncontrada,
    ErroDocumentoPeticaoNaoEncontrado,
    ErroParsingRespostaLLM
)
```

#### Novo Endpoint: `POST /api/peticoes/{peticao_id}/analisar-documentos`

**Path Parameter:**
- `peticao_id`: UUID da peti√ß√£o a analisar

**Status Code:** `202 Accepted` (processamento ass√≠ncrono)

**Fluxo do Endpoint:**

1. **Valida√ß√£o de Peti√ß√£o:**
   - Verifica se peti√ß√£o existe
   - Retorna 404 se n√£o encontrada

2. **Verifica√ß√£o de Re-an√°lise:**
   - Se peti√ß√£o j√° tem `documentos_sugeridos`, retorna resultado anterior
   - Evita reprocessamento desnecess√°rio

3. **Agendamento em Background:**
   - Define fun√ß√£o `executar_analise_em_background()` ass√≠ncrona
   - Adiciona em `background_tasks.add_task()`
   - Retorna 202 Accepted IMEDIATAMENTE (n√£o bloqueia request)

4. **Execu√ß√£o Background (ap√≥s response):**
   - Cria inst√¢ncia do servi√ßo
   - Chama `analisar_peticao_e_sugerir_documentos(peticao_id)`
   - Trata 5 tipos de erros poss√≠veis:
     - `ErroPeticaoNaoEncontrada` ‚Üí Registra erro no gerenciador
     - `ErroDocumentoPeticaoNaoEncontrado` ‚Üí Registra erro
     - `ErroParsingRespostaLLM` ‚Üí Registra erro
     - `ErroAnaliseDocumentosRelevantes` ‚Üí Registra erro
     - `Exception` gen√©rica ‚Üí Registra erro inesperado

**Response (202 Accepted - an√°lise iniciada):**
```json
{
  "sucesso": true,
  "mensagem": "An√°lise de documentos iniciada com sucesso. Consulte o status da peti√ß√£o para ver os documentos sugeridos quando a an√°lise terminar.",
  "peticao_id": "550e8400-e29b-41d4-a716-446655440000"
}
```

**Response (j√° analisada antes):**
```json
{
  "sucesso": true,
  "mensagem": "Peti√ß√£o j√° foi analisada anteriormente. Documentos sugeridos j√° est√£o dispon√≠veis.",
  "peticao_id": "...",
  "documentos_sugeridos": [...]
}
```

**Padr√£o Ass√≠ncrono:**
- Cliente chama POST ‚Üí recebe 202 Accepted
- An√°lise executa em background (10-60 segundos)
- Cliente faz polling via `GET /api/peticoes/status/{peticao_id}`
- Quando `documentos_sugeridos` aparecer no status ‚Üí an√°lise conclu√≠da

**Logging Detalhado:**
- In√≠cio da solicita√ß√£o (com peticao_id)
- Tentativa de re-an√°lise (warning)
- An√°lise agendada em background
- In√≠cio da an√°lise em background
- Conclus√£o com sucesso (com n√∫mero de documentos)
- Todos os tipos de erros (com stack trace)

---

### 4. `ARQUITETURA.md` (MODIFICADO - +120 linhas)

#### Se√ß√£o Atualizada: "Peti√ß√µes Iniciais (FASE 7)"

**Adicionado Endpoint:**
- `POST /api/peticoes/{peticao_id}/analisar-documentos` - Analisar peti√ß√£o e sugerir documentos (TAREFA-042)

**Documenta√ß√£o Completa do Endpoint:**

1. **Descri√ß√£o:** Usa LLM para analisar peti√ß√£o e identificar documentos necess√°rios
2. **Contexto de Neg√≥cio:** Segundo passo do fluxo de peti√ß√£o inicial
3. **Padr√£o Ass√≠ncrono:** Processamento em background com polling
4. **Prompt da LLM:** Explica√ß√£o detalhada do prompt system + user
5. **Prioridades:** Defini√ß√£o de essencial, importante, desejavel
6. **Exemplos de Documentos:** Lista de documentos t√≠picos sugeridos
7. **Integra√ß√£o com ChromaDB:** Como busca contexto RAG
8. **Uso no Frontend:** Fluxo completo de UX
9. **Tratamento de Erros:** Como erros background s√£o registrados

**Exemplos JSON:**
- Request (sem body)
- Response 202 Accepted
- Response j√° analisada (com documentos)
- Formato JSON da resposta da LLM

**Tabela de Prioridades:**
- essencial: Absolutamente necess√°rio
- importante: Muito √∫til
- desejavel: Complementar

---

## üß™ DECIS√ïES T√âCNICAS

### 1. Modelo LLM: GPT-4 (n√£o GPT-3.5)
**Justificativa:** GPT-4 tem melhor capacidade de racioc√≠nio jur√≠dico e compreens√£o contextual. A precis√£o das sugest√µes √© cr√≠tica para UX.

### 2. Temperatura: 0.3 (baixa)
**Justificativa:** Queremos respostas factuais e consistentes, n√£o criativas. Temperatura baixa reduz aleatoriedade.

### 3. Formato JSON na Resposta da LLM
**Justificativa:** JSON estruturado √© mais f√°cil de parsear que texto livre. Reduz erros de parsing e permite valida√ß√£o robusta.

### 4. Truncamento de Texto da Peti√ß√£o (8000 caracteres)
**Justificativa:** GPT-4 tem limite de ~8k tokens. Reservamos espa√ßo para sistema + contexto RAG + resposta. Primeiros 8k caracteres geralmente cont√™m informa√ß√µes mais importantes.

### 5. Busca RAG N√£o-Cr√≠tica
**Justificativa:** Se busca RAG falhar, an√°lise continua sem contexto adicional. RAG √© complementar, n√£o essencial.

### 6. Valida√ß√£o de Prioridade Permissiva
**Justificativa:** Se LLM retornar prioridade inv√°lida, usamos "importante" como padr√£o em vez de falhar. Um documento com prioridade padr√£o √© melhor que perder a sugest√£o.

### 7. Continuar se Documento Individual Inv√°lido
**Justificativa:** Se 1 de 10 documentos for inv√°lido, ainda temos 9 v√°lidos. Logamos warning mas n√£o falhamos a an√°lise toda.

### 8. Processamento Ass√≠ncrono em Background
**Justificativa:** An√°lise pode demorar 10-60 segundos (LLM + RAG). N√£o podemos bloquear request HTTP por tanto tempo (risco de timeout).

---

## üìä FLUXO COMPLETO DA AN√ÅLISE

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Cliente envia POST /api/peticoes/{id}/analisar-documentos       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Backend valida peti√ß√£o existe                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Backend agenda an√°lise em background                            ‚îÇ
‚îÇ    Retorna 202 Accepted imediatamente                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Background: Recupera texto da peti√ß√£o do ChromaDB               ‚îÇ
‚îÇ    (busca por documento_peticao_id, junta chunks)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Background: Busca RAG (chunks similares para contexto)          ‚îÇ
‚îÇ    (primeiros 1000 caracteres da peti√ß√£o como query)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. Background: Constr√≥i prompt (sistema + peti√ß√£o + RAG)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 7. Background: Chama GPT-4 com prompt                              ‚îÇ
‚îÇ    (timeout: 60s, temperature: 0.3)                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 8. Background: Parseia resposta JSON                               ‚îÇ
‚îÇ    (valida estrutura, campos, prioridades)                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 9. Background: Atualiza peti√ß√£o com documentos sugeridos           ‚îÇ
‚îÇ    (gerenciador.adicionar_documentos_sugeridos)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 10. Cliente faz polling de status                                  ‚îÇ
‚îÇ     GET /api/peticoes/status/{id}                                  ‚îÇ
‚îÇ     ‚Üí documentos_sugeridos agora est√° preenchido                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéâ RESULTADO FINAL

### Funcionalidades Implementadas
- ‚úÖ An√°lise autom√°tica de peti√ß√£o usando LLM
- ‚úÖ Sugest√£o de documentos com justificativas e prioridades
- ‚úÖ Integra√ß√£o com ChromaDB para contexto RAG
- ‚úÖ Processamento ass√≠ncrono em background
- ‚úÖ Prompt engineering robusto com formato JSON
- ‚úÖ Valida√ß√£o completa de resposta da LLM
- ‚úÖ Tratamento de erros em todos os n√≠veis
- ‚úÖ Logging detalhado para debug

### M√©tricas
- **Servi√ßo de An√°lise:** 860 linhas de c√≥digo
- **Fun√ß√£o de Banco Vetorial:** 110 linhas
- **Endpoint:** 200 linhas
- **Documenta√ß√£o:** 120 linhas
- **Total:** ~1290 linhas de c√≥digo + documenta√ß√£o

### Pr√≥ximos Passos
**TAREFA-043:** Backend - Endpoint de Upload de Documentos Complementares
- Permitir envio dos documentos sugeridos
- Associar documentos √† peti√ß√£o
- Atualizar status quando todos essenciais forem enviados

---

## üöÄ MARCO

üéâ **AN√ÅLISE DE DOCUMENTOS RELEVANTES IMPLEMENTADA!**

Sistema agora pode analisar peti√ß√µes iniciais automaticamente e sugerir documentos relevantes usando GPT-4. Primeiro passo cr√≠tico do fluxo de an√°lise de peti√ß√£o inicial com progn√≥stico conclu√≠do. Integra√ß√£o perfeita entre ChromaDB (RAG), LLM (an√°lise), e gerenciador de estado (rastreamento).
