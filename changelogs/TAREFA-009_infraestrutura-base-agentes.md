# TAREFA-009: INFRAESTRUTURA BASE PARA AGENTES

**Status:** ‚úÖ CONCLU√çDA  
**Data de Conclus√£o:** 2025-10-23  
**Respons√°vel:** IA (GitHub Copilot)  
**Depend√™ncias:** TAREFA-008  
**Pr√≥xima Tarefa:** TAREFA-010 (Agente Advogado - Coordenador)

---

## üìã DESCRI√á√ÉO DA TAREFA

Implementar a infraestrutura base necess√°ria para o sistema multi-agent, incluindo:
1. Wrapper robusto para comunica√ß√£o com a API da OpenAI (GerenciadorLLM)
2. Classe abstrata base para todos os agentes (AgenteBase)
3. Sistema de logging e tracking de custos
4. Tratamento de erros e retry logic

---

## üéØ OBJETIVOS

### Objetivo Principal
Criar a funda√ß√£o t√©cnica sobre a qual todos os agentes especializados (Advogado, Perito M√©dico, Perito Seguran√ßa do Trabalho) ser√£o constru√≠dos.

### Objetivos Espec√≠ficos
- ‚úÖ Wrapper para OpenAI API com retry logic e backoff exponencial
- ‚úÖ Sistema de logging detalhado de chamadas ao LLM
- ‚úÖ Tracking autom√°tico de custos (tokens e USD)
- ‚úÖ Classe abstrata AgenteBase com m√©todos template
- ‚úÖ Tratamento robusto de erros (rate limits, timeouts, API errors)
- ‚úÖ Fun√ß√µes utilit√°rias para formata√ß√£o de contexto
- ‚úÖ Health check para validar conex√£o com OpenAI

---

## üìÅ ARQUIVOS CRIADOS

### 1. `backend/src/utilitarios/gerenciador_llm.py`
**Linhas de c√≥digo:** ~600  
**Responsabilidade:** Gerenciar todas as intera√ß√µes com a API da OpenAI

**Classes principais:**
- `GerenciadorLLM`: Wrapper principal para OpenAI API
- `EstatisticaChamadaLLM`: Dataclass para tracking de chamadas individuais
- `EstatisticasGlobaisLLM`: Agregador de estat√≠sticas

**Funcionalidades implementadas:**
```python
# Chamada ao LLM com retry autom√°tico
gerenciador = GerenciadorLLM()
resposta = gerenciador.chamar_llm(
    prompt="Analise este documento...",
    modelo="gpt-4",
    temperatura=0.7
)

# Obter estat√≠sticas de uso
stats = gerenciador.obter_estatisticas_globais()
# Retorna: total de chamadas, tokens usados, custo em USD, etc.

# Verificar conex√£o com OpenAI
resultado = verificar_conexao_openai()
```

**Tratamento de erros:**
- `ErroLimiteTaxaExcedido`: Rate limit excedido ap√≥s todos os retries
- `ErroTimeoutAPI`: Timeout na chamada
- `ErroGeralAPI`: Outros erros da API OpenAI

**Retry Logic:**
- N√∫mero m√°ximo de tentativas: 3
- Backoff exponencial: 1s ‚Üí 2s ‚Üí 4s
- Retry autom√°tico para: RateLimitError, APITimeoutError

**Logging de custos:**
- Tokens de input/output separados
- Custo calculado por modelo (tabela interna atualizada)
- Timestamp de cada chamada
- Tempo de resposta em segundos

### 2. `backend/src/agentes/agente_base.py`
**Linhas de c√≥digo:** ~450  
**Responsabilidade:** Classe abstrata base para todos os agentes

**Classe principal:**
```python
class AgenteBase(ABC):
    @abstractmethod
    def montar_prompt(self, contexto_de_documentos, pergunta_do_usuario):
        """Cada agente implementa seu prompt espec√≠fico"""
        pass
    
    def processar(self, contexto_de_documentos, pergunta_do_usuario):
        """Template method - orquestra o fluxo de an√°lise"""
        # 1. Validar entradas
        # 2. Montar prompt (chama m√©todo abstrato)
        # 3. Chamar LLM via GerenciadorLLM
        # 4. Formatar resposta padronizada
        # 5. Calcular confian√ßa
        # 6. Registrar logs
        pass
```

**Funcionalidades fornecidas:**
- Integra√ß√£o autom√°tica com GerenciadorLLM
- Valida√ß√£o de entradas padronizada
- C√°lculo heur√≠stico de confian√ßa
- Formata√ß√£o de resposta estruturada
- Logging autom√°tico
- Estat√≠sticas de uso por agente

**Formato de resposta padronizado:**
```python
{
    "agente": "Nome do Agente",
    "descricao_agente": "Descri√ß√£o da expertise",
    "parecer": "An√°lise gerada pelo LLM",
    "confianca": 0.85,  # 0.0 a 1.0
    "timestamp": "2025-10-23T10:30:00",
    "modelo_utilizado": "gpt-4",
    "temperatura_utilizada": 0.7,
    "metadados": {
        "numero_de_documentos_analisados": 5,
        "tamanho_do_prompt_caracteres": 2500,
        "tamanho_da_resposta_caracteres": 1200,
        ...
    }
}
```

**Fun√ß√µes utilit√°rias:**
- `formatar_contexto_de_documentos()`: Formata chunks para o prompt
- `truncar_texto_se_necessario()`: Evita prompts muito longos

---

## üîß DECIS√ïES T√âCNICAS

### 1. Retry Logic com Backoff Exponencial
**Decis√£o:** Implementar retry autom√°tico com backoff exponencial (1s ‚Üí 2s ‚Üí 4s)

**Justificativa:**
- OpenAI imp√µe rate limits que podem ser atingidos em uso intenso
- Backoff exponencial √© o padr√£o de ind√∫stria para lidar com rate limits
- Evita sobrecarregar a API com retries imediatos

**Alternativas consideradas:**
- ‚ùå Retry linear (tempo fixo): Menos eficiente
- ‚ùå Sem retry: Muitas falhas desnecess√°rias

### 2. Tracking de Custos em Mem√≥ria
**Decis√£o:** Manter estat√≠sticas de custos em vari√°vel global em mem√≥ria

**Justificativa:**
- Simplicidade de implementa√ß√£o para MVP
- √ötil para debug e monitoramento durante desenvolvimento
- Pode ser facilmente migrado para sistema de m√©tricas dedicado

**Limita√ß√µes conhecidas:**
- Estat√≠sticas s√£o perdidas quando o servidor reinicia
- N√£o √© thread-safe para m√∫ltiplos workers

**Plano para produ√ß√£o:**
- Migrar para Prometheus/CloudWatch/DataDog
- Implementar persist√™ncia em banco de dados

### 3. C√°lculo Heur√≠stico de Confian√ßa
**Decis√£o:** Usar heur√≠sticas simples para calcular confian√ßa do parecer

**Heur√≠sticas implementadas:**
- Tamanho do parecer (muito curto = baixa confian√ßa)
- Presen√ßa de frases de incerteza ("n√£o tenho certeza", "talvez", etc.)
- Quantidade de contexto fornecido

**Justificativa:**
- OpenAI n√£o fornece scores de confian√ßa nativamente (exceto logprobs)
- Heur√≠sticas fornecem indica√ß√£o razo√°vel para MVP
- Melhor que n√£o ter indica√ß√£o nenhuma

**Plano para futuro:**
- Usar par√¢metro `logprobs` da OpenAI API
- Implementar valida√ß√£o sem√¢ntica com modelos de verifica√ß√£o
- An√°lise de contradi√ß√µes no texto gerado

### 4. Template Method Pattern
**Decis√£o:** Usar padr√£o Template Method na classe AgenteBase

**Justificativa:**
- Define esqueleto do algoritmo (processar) na classe base
- Delega partes espec√≠ficas (montar_prompt) para subclasses
- Garante consist√™ncia no fluxo de processamento
- Facilita manuten√ß√£o (mudan√ßas no fluxo afetam todos os agentes)

**Exemplo:**
```python
# Na classe base
def processar(self, ...):
    # 1. Validar (igual para todos)
    # 2. Montar prompt (ESPEC√çFICO - subclasse implementa)
    prompt = self.montar_prompt(...)
    # 3. Chamar LLM (igual para todos)
    resposta = self.gerenciador_llm.chamar_llm(prompt)
    # 4. Formatar (igual para todos)
    return self._formatar_resposta(resposta)
```

### 5. Tabela de Custos Hardcoded
**Decis√£o:** Manter tabela de custos por modelo hardcoded no c√≥digo

**Justificativa:**
- Custos da OpenAI s√£o relativamente est√°veis
- Evita depend√™ncia de API externa para pre√ßos
- Facilita c√°lculos offline

**Manuten√ß√£o necess√°ria:**
- Atualizar periodicamente conforme OpenAI muda pre√ßos
- Data da √∫ltima atualiza√ß√£o documentada no c√≥digo

---

## üß™ VALIDA√á√ïES E TESTES

### Testes Manuais Realizados
‚úÖ **Teste 1: Conex√£o com OpenAI**
```python
from backend.src.utilitarios.gerenciador_llm import verificar_conexao_openai

resultado = verificar_conexao_openai()
# Status: sucesso
# Conex√£o estabelecida com sucesso
```

‚úÖ **Teste 2: Chamada b√°sica ao LLM**
```python
from backend.src.utilitarios.gerenciador_llm import GerenciadorLLM

gerenciador = GerenciadorLLM()
resposta = gerenciador.chamar_llm(
    prompt="Responda apenas: OK",
    modelo="gpt-3.5-turbo",
    max_tokens=10
)
# Resposta: "OK"
```

‚úÖ **Teste 3: Tracking de custos**
```python
stats = gerenciador.obter_estatisticas_globais()
# total_de_chamadas: 1
# tokens_utilizados: 15
# custo_estimado_usd: 0.0001
```

‚úÖ **Teste 4: Classe AgenteBase (via subclasse mock)**
```python
class AgenteTesteMock(AgenteBase):
    def __init__(self):
        super().__init__()
        self.nome_do_agente = "Agente Teste"
        
    def montar_prompt(self, contexto, pergunta, metadados):
        return f"Teste: {pergunta}"

agente = AgenteTesteMock()
resultado = agente.processar(
    contexto_de_documentos=["doc1", "doc2"],
    pergunta_do_usuario="Analise isso"
)
# Status: sucesso
# Resposta estruturada gerada corretamente
```

### Testes de Erro

‚úÖ **Teste: Rate Limit (simulado)**
- Configurado retry m√°ximo para 1
- For√ßado RateLimitError
- Resultado: ErroLimiteTaxaExcedido lan√ßada corretamente

‚úÖ **Teste: Timeout**
- Configurado timeout de 1 segundo
- Prompt muito longo para processar
- Resultado: ErroTimeoutAPI lan√ßada ap√≥s retries

‚úÖ **Teste: API Key inv√°lida**
- Inicializado GerenciadorLLM com chave inv√°lida
- Resultado: ValueError lan√ßada no __init__

### Testes de Integra√ß√£o
‚ùå **ADIADOS** - Ser√£o implementados em tarefa futura dedicada a testes:
- Testes unit√°rios com pytest
- Mocks da OpenAI API
- Testes de integra√ß√£o end-to-end
- Testes de carga (m√∫ltiplas chamadas simult√¢neas)

---

## üìä M√âTRICAS DE IMPLEMENTA√á√ÉO

- **Linhas de c√≥digo adicionadas:** ~1050
- **Arquivos criados:** 2
- **Arquivos modificados:** 0
- **Fun√ß√µes/m√©todos criados:** 15+
- **Classes criadas:** 5
- **Exce√ß√µes customizadas:** 3
- **Tempo de implementa√ß√£o:** ~3 horas

---

## üîó INTEGRA√á√ïES

### Depend√™ncias Externas
- **OpenAI SDK** (`openai>=1.55.0`): J√° estava no requirements.txt
  - Usado para: Chat Completions API, Embeddings API

### Integra√ß√µes Internas
- `backend/src/configuracao/configuracoes.py`: Carrega OPENAI_API_KEY do .env
- Futuras integra√ß√µes (pr√≥ximas tarefas):
  - `backend/src/servicos/servico_banco_vetorial.py`: Buscar contexto de documentos
  - `backend/src/agentes/agente_advogado.py`: Primeira subclasse de AgenteBase
  - `backend/src/agentes/agente_perito_medico.py`: Segunda subclasse
  - `backend/src/agentes/agente_perito_seguranca_trabalho.py`: Terceira subclasse

---

## üìù COMO USAR (Para Pr√≥ximas Tarefas)

### Para criar um novo agente:

```python
from backend.src.agentes.agente_base import AgenteBase

class AgenteNovoPerito(AgenteBase):
    def __init__(self):
        super().__init__()
        
        # Definir identidade do agente
        self.nome_do_agente = "Perito em [√Årea]"
        self.descricao_do_agente = "Especialista em an√°lise de [...]"
        
        # (Opcional) Customizar modelo e temperatura
        self.modelo_llm_padrao = "gpt-4"
        self.temperatura_padrao = 0.7
    
    def montar_prompt(self, contexto_de_documentos, pergunta_do_usuario, metadados_adicionais):
        """
        Implementar l√≥gica espec√≠fica de montagem de prompt.
        Use formatar_contexto_de_documentos() para estruturar os documentos.
        """
        from backend.src.agentes.agente_base import formatar_contexto_de_documentos
        
        contexto_formatado = formatar_contexto_de_documentos(contexto_de_documentos)
        
        prompt = f"""
        Voc√™ √© um {self.nome_do_agente}.
        
        Documentos para an√°lise:
        {contexto_formatado}
        
        Pergunta do usu√°rio:
        {pergunta_do_usuario}
        
        Forne√ßa uma an√°lise t√©cnica detalhada sob a perspectiva de [sua √°rea].
        """
        
        return prompt

# Usar o agente
agente = AgenteNovoPerito()
resultado = agente.processar(
    contexto_de_documentos=["chunk1", "chunk2"],
    pergunta_do_usuario="Analise este caso"
)

print(resultado["parecer"])
```

### Para usar o GerenciadorLLM diretamente:

```python
from backend.src.utilitarios.gerenciador_llm import GerenciadorLLM

gerenciador = GerenciadorLLM()

# Chamada simples
resposta = gerenciador.chamar_llm(
    prompt="Seu prompt aqui",
    modelo="gpt-4",
    temperatura=0.7
)

# Chamada com mensagem de sistema customizada
resposta = gerenciador.chamar_llm(
    prompt="Analise este contrato",
    modelo="gpt-4",
    temperatura=0.5,
    mensagens_de_sistema="Voc√™ √© um advogado especializado em contratos",
    max_tokens=500
)

# Verificar custos
stats = gerenciador.obter_estatisticas_globais()
print(f"Custo total: ${stats['custo_total_estimado_usd']}")
```

---

## üêõ PROBLEMAS CONHECIDOS E LIMITA√á√ïES

### 1. Estat√≠sticas em Mem√≥ria
**Problema:** Estat√≠sticas s√£o perdidas quando o servidor reinicia  
**Impacto:** M√©dio - Perda de hist√≥rico de custos  
**Workaround:** Exportar estat√≠sticas periodicamente via endpoint  
**Solu√ß√£o futura:** Migrar para sistema de m√©tricas persistente

### 2. Confian√ßa Heur√≠stica
**Problema:** C√°lculo de confian√ßa √© simplificado e n√£o reflete confian√ßa real do modelo  
**Impacto:** Baixo - Confian√ßa √© apenas indicativa  
**Workaround:** Usu√°rios devem sempre revisar pareceres  
**Solu√ß√£o futura:** Usar logprobs da OpenAI API

### 3. Tabela de Custos Desatualizada
**Problema:** Custos hardcoded podem ficar desatualizados  
**Impacto:** Baixo - Estimativas de custo imprecisas  
**Workaround:** Atualizar manualmente quando OpenAI muda pre√ßos  
**Solu√ß√£o futura:** Buscar custos via API da OpenAI (se dispon√≠vel)

### 4. Thread Safety
**Problema:** Estat√≠sticas globais n√£o s√£o thread-safe  
**Impacto:** Baixo - Contadores podem ficar imprecisos com m√∫ltiplos workers  
**Workaround:** Usar 1 worker apenas durante desenvolvimento  
**Solu√ß√£o futura:** Usar locks ou sistema de m√©tricas dedicado

---

## üìö DOCUMENTA√á√ÉO ATUALIZADA

### Arquivos de documenta√ß√£o modificados:
- ‚úÖ `ARQUITETURA.md`: Adicionada se√ß√£o sobre sistema de agentes
- ‚úÖ `ROADMAP.md`: Marcada TAREFA-009 como conclu√≠da
- ‚úÖ `README.md`: Atualizado status do projeto
- ‚úÖ `CHANGELOG_IA.md`: Adicionada entrada para TAREFA-009

---

## ‚úÖ CHECKLIST DE CONCLUS√ÉO

- [x] GerenciadorLLM implementado e testado
- [x] AgenteBase implementado e testado
- [x] Retry logic com backoff exponencial funcionando
- [x] Sistema de logging implementado
- [x] Tracking de custos funcionando
- [x] Exce√ß√µes customizadas definidas
- [x] Fun√ß√µes utilit√°rias criadas
- [x] Health check implementado
- [x] C√≥digo comentado exaustivamente (padr√£o LLM)
- [x] Documenta√ß√£o atualizada (ARQUITETURA.md, ROADMAP.md, README.md)
- [x] Changelog criado
- [ ] Testes unit√°rios (ADIADO para tarefa futura)
- [ ] Testes de integra√ß√£o (ADIADO para tarefa futura)

---

## üöÄ PR√ìXIMOS PASSOS

### Tarefa imediatamente seguinte:
**TAREFA-010: Agente Advogado (Coordenador)**

Este agente ser√° o orquestrador do sistema multi-agent:
1. Receber√° solicita√ß√£o do usu√°rio
2. Consultar√° o RAG (ChromaDB) para buscar contexto relevante
3. Delegar√° an√°lises para peritos especializados
4. Compilar√° respostas dos peritos em um parecer final coeso

### Futuras melhorias desta infraestrutura:
- Implementar testes unit√°rios completos
- Adicionar suporte para streaming de respostas (Server-Sent Events)
- Implementar cache de respostas para perguntas similares
- Migrar estat√≠sticas para sistema de m√©tricas dedicado (Prometheus)
- Adicionar suporte para modelos locais (Ollama, LLaMA)
- Implementar rate limiting por usu√°rio

---

## üë§ NOTAS PARA PR√ìXIMA IA

Se voc√™ for trabalhar na TAREFA-010 ou em qualquer agente espec√≠fico:

1. **Herde de AgenteBase**: Todos os agentes devem estender AgenteBase
2. **Implemente montar_prompt()**: Este √© o m√©todo-chave que define o comportamento do agente
3. **Use formatar_contexto_de_documentos()**: Fun√ß√£o utilit√°ria para estruturar documentos
4. **Defina nome e descri√ß√£o**: No __init__, defina self.nome_do_agente e self.descricao_do_agente
5. **Temperatura recomendada**:
   - 0.0-0.3: Para an√°lises t√©cnicas precisas (ex: an√°lise de conformidade com NRs)
   - 0.5-0.7: Para an√°lises equilibradas (padr√£o)
   - 0.8-1.0: Para an√°lises criativas (ex: sugest√µes de argumenta√ß√£o)

6. **Exemplo de prompt efetivo para agente**:
```python
def montar_prompt(self, contexto, pergunta, metadados):
    return f"""
    IDENTIDADE: Voc√™ √© um {self.nome_do_agente} com [X anos de experi√™ncia].
    
    CONTEXTO:
    {formatar_contexto_de_documentos(contexto)}
    
    TAREFA:
    {pergunta}
    
    INSTRU√á√ïES:
    1. Analise os documentos fornecidos
    2. Cite trechos espec√≠ficos ao fazer afirma√ß√µes
    3. Forne√ßa an√°lise t√©cnica sob a √≥tica de [sua √°rea]
    4. Se informa√ß√£o for insuficiente, indique claramente
    
    FORMATO DA RESPOSTA:
    - Resumo executivo
    - An√°lise detalhada
    - Conclus√µes e recomenda√ß√µes
    """
```

**Boa sorte! A base est√° s√≥lida. üéâ**

---

**Data de cria√ß√£o deste changelog:** 2025-10-23  
**Autor:** IA (GitHub Copilot)  
**Revisado por:** N/A
